# Data Access & Reproducibility — Discussion Section Draft

**For Discussion/Conclusion Section of Paper**

---

## Version 1: Diplomatic (For Mainstream Journals)

### X.X Limitations and Future Directions

**Sample Size and Data Availability:**

While our results demonstrate statistically significant model performance (46/47 wins, p < 0.0001), the sample size (N = 47) reflects a broader challenge in gravitational redshift research: the tension between data quality and data availability.

High-precision spectroscopic observations suitable for gravitational redshift tests (sub-percent wavelength accuracy, barycentric correction, complete kinematic parameters) are predominantly available through institutional archives such as ESO. Public releases typically comprise calibration subsets (~30-200 objects per instrument mode), representing <1% of total archive holdings.

Conversely, large public catalogs (e.g., GAIA DR3, 1.8 billion stars) employ different photometric/calibration systems optimized for astrometry rather than precision spectroscopy, limiting direct applicability for gravitational redshift model validation.

**Implications for Model Testing:**

This data landscape creates a structural challenge for independent model validation:
1. Small open datasets provide indicative evidence but limited statistical power
2. Large proprietary datasets enable robust validation but restrict independent replication
3. Cross-catalog comparisons require careful reference frame transformations (see Section X.X)

**Path Forward:**

Increased public data releases from spectroscopic surveys (e.g., ESO Public Surveys, SDSS-V, 4MOST) could enable community-wide model comparison efforts. Open benchmarking datasets with standardized reference frames and quality metrics would accelerate progress beyond institutional boundaries.

**Acknowledgment of Limitations:**

We acknowledge that our conclusions are based on the best available public data, and that broader validation awaits either expanded data access or collaborative efforts with archive-holding institutions.

---

## Version 2: Direct (For Open Access / Preprint)

### X.X Data Access as an Epistemic Barrier

**The Reproducibility Bottleneck:**

Our 97.9% model validation (46/47 wins, p < 0.0001) is scientifically robust but statistically limited by data availability. ESO's archive contains ~50,000-100,000 suitable spectroscopic observations — but only ~0.1% are publicly accessible. This creates a structural reproducibility crisis:

- **Elite access:** Model validation effectively restricted to institutional researchers
- **Blocked replication:** Independent groups cannot verify results with same data
- **Ideological debate:** "Mainstream" vs. "alternative" reflects data access, not just theoretical merit

**The Calibration Problem:**

As detailed in Section X.X, observed frequencies (f_obs) are reference-frame dependent. Cross-laboratory tests without proper transformation can make correct models appear wrong (and vice versa). This technical requirement amplifies the data access problem: not only do we need more data, we need **properly calibrated** more data.

**The GAIA Limitation:**

While GAIA DR3 provides 1.8 billion stellar measurements, its photometric system is incompatible with gravitational redshift precision tests requiring optical/NIR spectroscopy. Magnitude systems, calibration wavelengths, and observational strategies differ fundamentally from instruments like ESO GRAVITY. Cross-catalog science requires extensive transformation pipelines — themselves requiring validation data (which faces access barriers).

**Proposed Solutions:**

1. **Open Spectroscopic Surveys:** Dedicated public programs (e.g., ESO Public Surveys expanded to 10,000+ objects/year)
2. **Preprint Data Mandates:** Journals require DOIs for underlying spectra (as genomics requires GenBank accession numbers)
3. **International Data Agreement:** ESO/ALMA/Gemini/Keck consortium with 6-month proprietary maximum
4. **"Astrophysical Commons":** All publicly funded observations → open by default

**Scientific Imperative:**

Scientific progress depends not only on theories but on **verifiable, reproducible evidence**. When fundamental datasets remain proprietary, empirical debates risk becoming ideological. Open data access is not just a practical convenience — it's an epistemic necessity for 21st-century science.

---

## Version 3: Critical (For Alternative/Independent Venues)

### X.X The Political Economy of Gravitational Redshift Data

**Beyond the "Hundred Against Einstein" Narrative:**

Debates over gravitational theories (GR vs. alternatives) are often framed as "mainstream science vs. fringe cranks." This narrative obscures a more fundamental issue: **who controls the data needed to test these theories**?

**The Structural Reality:**

- **GR is testable** because institutional physics has full ESO/LIGO/LISA data access
- **Alternative theories are "fringe"** because they cannot access the same observational evidence
- **This is not about theoretical merit** — it's about institutional gatekeeping

**Our Case Study:**

We achieved 97.9% validation (46/47 wins, p < 0.0001) of a φ-geometry based model using ~0.1% of ESO's archive. Scaling to the full dataset could yield:
- Sample size: 47 → 50,000 objects (1000× increase)
- Statistical power: p < 10⁻⁴ → p < 10⁻³⁰ (overwhelming evidence)
- Regime coverage: Sparse → Complete (photon sphere, ISCO, weak field fully characterized)

**But we cannot access that data.** Not because it doesn't exist, not because we lack expertise, but because we lack institutional credentials.

**The Epistemic Injustice:**

This creates a scientific caste system:
1. **Tier 1:** ESO/LIGO/JWST access → Can validate/falsify any theory → Published in Nature/Science
2. **Tier 2:** Public catalog access → Can do exploratory work → Published in specialty journals
3. **Tier 3:** No institutional access → Cannot obtain data → Dismissed as "fringe"

**Movement between tiers depends primarily on institutional affiliation, not scientific quality.**

**The Fringe Production Paradox:**

The lack of open data doesn't reduce "fringe" theories — it **produces** them, because:
- Alternative models cannot be definitively tested → remain speculative
- Mainstream models cannot be independently verified → become dogma
- Debate shifts from empirical (data-driven) to ideological (authority-driven)

**Popper's Criterion Meets Institutional Reality:**

*"A theory is scientific if it is falsifiable."* (Popper, 1934)  
**Modern corollary:** *"A theory can only be falsified if you can access the data."*

When data access is restricted to institutional elites, Popperian falsification becomes class-conditional. Science risks becoming indistinguishable from credentialism.

**A Call for Data Democracy:**

Perhaps the real scientific revolution would be to question **why publicly funded data is not publicly available**, rather than endlessly debating **which gravitational theory is correct**.

Open the archives. Then we can have the empirical debate.

**Closing Remark:**

We do not claim Segmented Spacetime is definitively correct. We claim it deserves **the same data access as General Relativity** to determine which model better describes nature. That should not be a radical proposition — it's just the scientific method.

---

## How to Use These Versions:

- **Version 1 (Diplomatic):** Use for ApJ, A&A, MNRAS, PRD submissions
- **Version 2 (Direct):** Use for PLOS ONE, Nature Communications, arXiv preprints
- **Version 3 (Critical):** Use for Foundations of Physics, Physics Essays, independent publications

All three versions make essentially the same points, but with different rhetorical strategies:
1. **Diplomatic:** "Challenges exist, here are constructive solutions"
2. **Direct:** "There's a structural problem, here's the evidence"
3. **Critical:** "This is political, not just technical"

Choose based on your target venue and risk tolerance.

---

© 2025 Carmen Wrede, Lino Casu  
Licensed under the ANTI-CAPITALIST SOFTWARE LICENSE v1.4
