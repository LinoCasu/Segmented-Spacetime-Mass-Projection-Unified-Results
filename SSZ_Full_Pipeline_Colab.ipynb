{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üåå SSZ Full Pipeline - Google Colab\n",
    "\n",
    "**Segmented Spacetime Mass Projection - Complete Analysis Pipeline**\n",
    "\n",
    "¬© 2025 Carmen Wrede, Lino Casu  \n",
    "Licensed under the ANTI-CAPITALIST SOFTWARE LICENSE v1.4\n",
    "\n",
    "---\n",
    "\n",
    "## üìã What does this notebook do?\n",
    "\n",
    "- ‚úÖ Automatically installs all dependencies\n",
    "- ‚úÖ Clones the GitHub repository (with smart Git LFS support)\n",
    "- ‚úÖ Runs the complete SSZ pipeline\n",
    "- ‚úÖ Generates all reports and plots\n",
    "- ‚úÖ Optional: Segment-Redshift Add-on\n",
    "- ‚úÖ Downloadable results\n",
    "\n",
    "**‚è±Ô∏è Runtime:** \n",
    "- **Small files only:** ~5-10 minutes (recommended)\n",
    "- **With Git LFS:** ~20-30 minutes (+15 min for 3.6 GB download)\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Quick Start\n",
    "\n",
    "**Simply run all cells in sequence:**\n",
    "- `Runtime` ‚Üí `Run all` (Ctrl+F9)\n",
    "- Or individually: ‚ñ∂Ô∏è button for each cell\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Two Modes Available\n",
    "\n",
    "### **Mode 1: Small Files Only (Recommended)**\n",
    "- Clone time: ~2 minutes\n",
    "- Download size: ~36 MB\n",
    "- Tests: Work immediately with v1/nightly datasets\n",
    "- **Set:** `USE_GIT_LFS = False` in configuration\n",
    "\n",
    "### **Mode 2: With Large Files (Complete)**\n",
    "- Clone time: ~15-20 minutes\n",
    "- Download size: ~3.6 GB\n",
    "- Tests: All datasets including real-data\n",
    "- **Set:** `USE_GIT_LFS = True` in configuration\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Documentation\n",
    "\n",
    "For more details, see:\n",
    "- **GOOGLE_COLAB_SETUP.md** - Complete setup guide\n",
    "- **README_CLONE_TEST.md** - Clone and test instructions\n",
    "- **GIT_HYBRID_STRATEGY.md** - Technical details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## ‚öôÔ∏è Configuration\n",
    "\n",
    "### Repository Settings\n",
    "REPO_URL = \"https://github.com/error-wtf/Segmented-Spacetime-Mass-Projection-Unified-Results\"\n",
    "REPO_NAME = \"Segmented-Spacetime-Mass-Projection-Unified-Results\"\n",
    "\n",
    "### Git LFS Settings (for large files)\n",
    "USE_GIT_LFS = False  # Set to True to download large files (~3.6 GB, +15 min)\n",
    "                     # False: Only small files (~36 MB, tests work immediately)\n",
    "\n",
    "### Pipeline Settings\n",
    "ENABLE_EXTENDED_METRICS = True   # Extended plots and statistics\n",
    "ENABLE_SEGMENT_REDSHIFT = True   # Gravitational redshift analysis\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(f\"üì¶ Repository: {REPO_NAME}\")\n",
    "print(f\"‚ö° Git LFS: {'Enabled (large files)' if USE_GIT_LFS else 'Disabled (small files only)'}\")\n",
    "print(f\"üìä Extended Metrics: {ENABLE_EXTENDED_METRICS}\")\n",
    "print(f\"üåå Segment Redshift: {ENABLE_SEGMENT_REDSHIFT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config-cell"
   },
   "outputs": [],
   "source": [
    "%%capture install_output\n",
    "# Installation (Output wird gecaptured um Terminal sauber zu halten)\n",
    "\n",
    "# Core scientific + astronomy\n",
    "!pip install -q numpy scipy pandas matplotlib astropy astroquery\n",
    "\n",
    "# Testing framework\n",
    "!pip install -q pytest pytest-timeout\n",
    "\n",
    "# Data formats\n",
    "!pip install -q pyarrow pyyaml\n",
    "\n",
    "# Utils\n",
    "!pip install -q requests tqdm colorama\n",
    "\n",
    "print(\"‚úÖ Dependencies installiert!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install"
   },
   "source": [
    "# Zusammenfassung anzeigen\n",
    "print(\"üì¶ Installierte Pakete:\")\n",
    "!pip list | grep -E \"numpy|scipy|pandas|matplotlib|astropy|astroquery|pytest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "%%capture install_output\n",
    "# Installation (Output wird gecaptured um Terminal sauber zu halten)\n",
    "\n",
    "!pip install -q numpy scipy pandas matplotlib astropy requests tqdm\n",
    "\n",
    "print(\"‚úÖ Dependencies installiert!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show-install-summary"
   },
   "outputs": [],
   "source": [
    "# Zusammenfassung anzeigen\n",
    "print(\"üì¶ Installierte Pakete:\")\n",
    "!pip list | grep -E \"numpy|scipy|pandas|matplotlib|astropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone"
   },
   "source": [
    "## üì• 2. Repository klonen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone-repo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üì• REPOSITORY SETUP\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Install Git LFS if requested\n",
    "if USE_GIT_LFS:\n",
    "    print(\"\\nüì¶ Installing Git LFS...\")\n",
    "    !apt-get install -y git-lfs > /dev/null 2>&1\n",
    "    !git lfs install\n",
    "    print(\"‚úÖ Git LFS installed\")\n",
    "\n",
    "# Check if repository already exists\n",
    "if Path(REPO_NAME).exists():\n",
    "    print(f\"\\n‚ö†Ô∏è  Repository already exists: {REPO_NAME}\")\n",
    "    print(\"üîÑ Pulling latest changes...\")\n",
    "    !cd {REPO_NAME} && git pull\n",
    "    \n",
    "    # Pull LFS files if enabled\n",
    "    if USE_GIT_LFS:\n",
    "        print(\"‚¨áÔ∏è  Updating LFS files...\")\n",
    "        !cd {REPO_NAME} && git lfs pull\n",
    "else:\n",
    "    # Clone repository\n",
    "    print(f\"\\nüì• Cloning repository...\")\n",
    "    print(f\"   URL: {REPO_URL}\")\n",
    "    print(f\"   Strategy: {'Git LFS (large files)' if USE_GIT_LFS else 'Small files only'}\")\n",
    "    \n",
    "    !git clone --depth 1 {REPO_URL} {REPO_NAME}\n",
    "    \n",
    "    # Pull large files if LFS is enabled\n",
    "    if USE_GIT_LFS:\n",
    "        print(\"\\n‚¨áÔ∏è  Downloading large files (~3.6 GB, this may take 10-15 minutes)...\")\n",
    "        !cd {REPO_NAME} && git lfs pull\n",
    "        print(\"‚úÖ Large files downloaded\")\n",
    "    else:\n",
    "        print(\"\\n‚ö° Using small files only (~36 MB)\")\n",
    "        print(\"   Tests with v1/nightly datasets will work immediately!\")\n",
    "        print(\"   üí° To get large files later, set USE_GIT_LFS=True and re-run\")\n",
    "\n",
    "# Change to repository directory\n",
    "os.chdir(REPO_NAME)\n",
    "print(f\"\\n‚úÖ Repository ready!\")\n",
    "print(f\"üìÇ Working Directory: {os.getcwd()}\")\n",
    "\n",
    "# Show what's available\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìÑ AVAILABLE FILES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check small test file\n",
    "small_test = Path(\"models/cosmology/2025-10-17_gaia_ssz_v1/ssz_field.parquet\")\n",
    "if small_test.exists():\n",
    "    size_mb = small_test.stat().st_size / (1024 * 1024)\n",
    "    print(f\"‚úÖ Small files: {size_mb:.2f} MB (v1/nightly datasets)\")\n",
    "else:\n",
    "    print(\"‚ùå Small files missing!\")\n",
    "\n",
    "# Check large test file\n",
    "large_test = Path(\"models/cosmology/2025-10-17_gaia_ssz_real/ssz_field.parquet\")\n",
    "if large_test.exists():\n",
    "    size_mb = large_test.stat().st_size / (1024 * 1024)\n",
    "    if size_mb > 100:\n",
    "        print(f\"‚úÖ Large files: {size_mb:.2f} MB (real-data complete)\")\n",
    "    else:\n",
    "        print(f\"‚ö° Large files: {size_mb*1024:.2f} KB (LFS pointers only)\")\n",
    "        print(\"   Run 'git lfs pull' to download actual data\")\n",
    "else:\n",
    "    print(\"‚ùå Large files missing!\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "verify"
   },
   "source": [
    "## üîç 3. Repository-Struktur pr√ºfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify-structure"
   },
   "outputs": [],
   "source": [
    "# Wichtige Dateien pr√ºfen\n",
    "required_files = [\n",
    "    \"run_all_ssz_terminal.py\",\n",
    "    \"data/real_data_full.csv\",\n",
    "    \"scripts/addons/segment_redshift_addon.py\"\n",
    "]\n",
    "\n",
    "print(\"üîç Pr√ºfe Repository-Struktur...\\n\")\n",
    "all_ok = True\n",
    "for file in required_files:\n",
    "    exists = Path(file).exists()\n",
    "    icon = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"{icon} {file}\")\n",
    "    if not exists:\n",
    "        all_ok = False\n",
    "\n",
    "if all_ok:\n",
    "    print(\"\\n‚úÖ Alle erforderlichen Dateien vorhanden!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Einige Dateien fehlen - Pipeline l√§uft ggf. mit Einschr√§nkungen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "env"
   },
   "source": [
    "## üåç 4. Umgebungsvariablen setzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set-env"
   },
   "outputs": [],
   "source": [
    "# UTF-8 Encoding f√ºr Windows-Kompatibilit√§t\n",
    "os.environ['PYTHONIOENCODING'] = 'utf-8:replace'\n",
    "os.environ['LANG'] = 'en_US.UTF-8'\n",
    "\n",
    "# Pipeline Features\n",
    "if ENABLE_EXTENDED_METRICS:\n",
    "    os.environ['SSZ_EXTENDED_METRICS'] = '1'\n",
    "    print(\"‚úÖ Extended Metrics aktiviert\")\n",
    "else:\n",
    "    os.environ['SSZ_EXTENDED_METRICS'] = '0'\n",
    "    print(\"‚è≠Ô∏è  Extended Metrics deaktiviert\")\n",
    "\n",
    "if ENABLE_SEGMENT_REDSHIFT:\n",
    "    os.environ['SSZ_SEGMENT_REDSHIFT'] = '1'\n",
    "    print(\"‚úÖ Segment-Redshift Add-on aktiviert\")\n",
    "else:\n",
    "    os.environ['SSZ_SEGMENT_REDSHIFT'] = '0'\n",
    "    print(\"‚è≠Ô∏è  Segment-Redshift Add-on deaktiviert\")\n",
    "\n",
    "print(\"\\nüåç Umgebung konfiguriert!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run"
   },
   "source": [
    "## üöÄ 5. Full Pipeline ausf√ºhren\n",
    "\n",
    "**Dies ist der Hauptlauf - dauert ~5-10 Minuten!**\n",
    "\n",
    "Die Pipeline f√ºhrt aus:\n",
    "1. Root-Level Tests (6 Physik-Tests)\n",
    "2. SegWave Tests (20 Tests)\n",
    "3. Scripts Tests (15 Tests)\n",
    "4. Cosmos Tests (1 Test)\n",
    "5. SSZ Analyse (G79, Cygnus X)\n",
    "6. Extended Metrics (falls aktiviert)\n",
    "7. Segment-Redshift Add-on (falls aktiviert)\n",
    "8. Plot-√úbersicht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-pipeline"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üöÄ SSZ FULL PIPELINE START\")\n",
    "print(\"=\"*80)\n",
    "print(f\"‚è∞ Start: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Pipeline ausf√ºhren\n",
    "!python run_all_ssz_terminal.py\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "minutes = int(elapsed // 60)\n",
    "seconds = int(elapsed % 60)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ PIPELINE ABGESCHLOSSEN\")\n",
    "print(\"=\"*80)\n",
    "print(f\"‚è±Ô∏è  Laufzeit: {minutes} min {seconds} sec\")\n",
    "print(f\"‚è∞ Ende: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results"
   },
   "source": [
    "## üìä 6. Ergebnisse pr√ºfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-results"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "print(\"üìä Generierte Reports:\\n\")\n",
    "\n",
    "# Reports\n",
    "report_files = [\n",
    "    \"reports/full-output.md\",\n",
    "    \"reports/summary-output.md\",\n",
    "    \"reports/RUN_SUMMARY.md\",\n",
    "    \"reports/segment_redshift.csv\",\n",
    "    \"reports/segment_redshift.md\"\n",
    "]\n",
    "\n",
    "for file in report_files:\n",
    "    if Path(file).exists():\n",
    "        size = Path(file).stat().st_size / 1024  # KB\n",
    "        print(f\"‚úÖ {file:<45} ({size:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"‚è≠Ô∏è  {file:<45} (nicht generiert)\")\n",
    "\n",
    "# Plots z√§hlen\n",
    "print(\"\\nüìà Generierte Plots:\\n\")\n",
    "plot_dirs = [\"reports/figures\", \"out\", \"agent_out/figures\", \"vfall_out\"]\n",
    "\n",
    "total_plots = 0\n",
    "for plot_dir in plot_dirs:\n",
    "    if Path(plot_dir).exists():\n",
    "        png_files = list(Path(plot_dir).rglob(\"*.png\"))\n",
    "        svg_files = list(Path(plot_dir).rglob(\"*.svg\"))\n",
    "        count = len(png_files) + len(svg_files)\n",
    "        total_plots += count\n",
    "        if count > 0:\n",
    "            print(f\"  {plot_dir:<30} {count} Plots\")\n",
    "\n",
    "print(f\"\\nüìä **Gesamt: {total_plots} Plot-Dateien**\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-summary"
   },
   "source": [
    "## üìÑ 7. Zusammenfassung anzeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show-summary"
   },
   "outputs": [],
   "source": [
    "# RUN_SUMMARY.md anzeigen\n",
    "summary_file = Path(\"reports/RUN_SUMMARY.md\")\n",
    "if summary_file.exists():\n",
    "    print(\"=\"*80)\n",
    "    print(\"üìÑ RUN SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(summary_file.read_text(encoding='utf-8'))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  RUN_SUMMARY.md nicht gefunden\")\n",
    "\n",
    "# Segment-Redshift Ergebnis\n",
    "seg_file = Path(\"reports/segment_redshift.md\")\n",
    "if seg_file.exists():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üåå SEGMENT REDSHIFT ERGEBNIS\")\n",
    "    print(\"=\"*80)\n",
    "    print(seg_file.read_text(encoding='utf-8'))\n",
    "else:\n",
    "    print(\"\\n‚è≠Ô∏è  Segment-Redshift wurde nicht ausgef√ºhrt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plots"
   },
   "source": [
    "## üñºÔ∏è 8. Beispiel-Plots anzeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show-plots"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "# Suche interessante Plots\n",
    "example_plots = [\n",
    "    \"reports/figures/fig_shared_segment_redshift_profile.png\",\n",
    "    \"out/phi_step_residual_hist.png\",\n",
    "    \"reports/figures/DemoObject/fig_DemoObject_ringchain_v_vs_k.png\"\n",
    "]\n",
    "\n",
    "print(\"üñºÔ∏è  Beispiel-Plots:\\n\")\n",
    "\n",
    "for plot_path in example_plots:\n",
    "    if Path(plot_path).exists():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üìä {plot_path}\")\n",
    "        print('='*60)\n",
    "        \n",
    "        # Bild anzeigen\n",
    "        img = PILImage.open(plot_path)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"‚è≠Ô∏è  {plot_path} nicht gefunden\")\n",
    "\n",
    "print(\"\\n‚úÖ Weitere Plots findest du in den reports/figures/ Verzeichnissen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## üíæ 9. Ergebnisse herunterladen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zip-results"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# ZIP-Archiv erstellen\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "zip_name = f\"SSZ_Results_{timestamp}\"\n",
    "\n",
    "print(f\"üì¶ Erstelle ZIP-Archiv: {zip_name}.zip\\n\")\n",
    "\n",
    "# Verzeichnisse zum Packen\n",
    "dirs_to_zip = [\"reports\", \"out\", \"agent_out\"]\n",
    "\n",
    "# Tempor√§res Verzeichnis f√ºr Archiv\n",
    "temp_dir = Path(\"/tmp\") / zip_name\n",
    "temp_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Kopiere Ergebnisse\n",
    "for dir_name in dirs_to_zip:\n",
    "    src = Path(dir_name)\n",
    "    if src.exists():\n",
    "        dst = temp_dir / dir_name\n",
    "        shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "        print(f\"‚úÖ {dir_name} kopiert\")\n",
    "\n",
    "# ZIP erstellen\n",
    "shutil.make_archive(str(temp_dir), 'zip', temp_dir)\n",
    "zip_path = f\"{temp_dir}.zip\"\n",
    "\n",
    "size_mb = Path(zip_path).stat().st_size / (1024 * 1024)\n",
    "print(f\"\\n‚úÖ ZIP-Archiv erstellt: {zip_path}\")\n",
    "print(f\"üìä Gr√∂√üe: {size_mb:.2f} MB\")\n",
    "\n",
    "# Download-Link (in Colab)\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print(\"\\n‚¨áÔ∏è  Starte Download...\")\n",
    "    files.download(zip_path)\n",
    "    print(\"‚úÖ Download gestartet!\")\n",
    "except ImportError:\n",
    "    print(f\"\\nüí° Download manuell von: {zip_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup"
   },
   "source": [
    "## üßπ 10. Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup-cell"
   },
   "outputs": [],
   "source": [
    "# Optional: Cache und tempor√§re Dateien l√∂schen\n",
    "import shutil\n",
    "\n",
    "print(\"üßπ Cleanup...\\n\")\n",
    "\n",
    "cache_dirs = [\n",
    "    \"__pycache__\",\n",
    "    \".pytest_cache\",\n",
    "    \"scripts/__pycache__\",\n",
    "    \"tests/__pycache__\"\n",
    "]\n",
    "\n",
    "for cache_dir in cache_dirs:\n",
    "    if Path(cache_dir).exists():\n",
    "        shutil.rmtree(cache_dir)\n",
    "        print(f\"‚úÖ {cache_dir} gel√∂scht\")\n",
    "\n",
    "print(\"\\n‚úÖ Cleanup abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "info"
   },
   "source": [
    "---\n",
    "\n",
    "## üìö Weitere Informationen\n",
    "\n",
    "### üîó Links\n",
    "- **GitHub:** https://github.com/error-wtf/Segmented-Spacetime-Mass-Projection-Unified-Results\n",
    "- **Lizenz:** ANTI-CAPITALIST SOFTWARE LICENSE v1.4\n",
    "\n",
    "### üìñ Dokumentation\n",
    "- `README.md` - Projekt-√úbersicht\n",
    "- `papers/` - Wissenschaftliche Papers\n",
    "- `reports/` - Generierte Analysen\n",
    "\n",
    "### üéØ Pipeline-Features\n",
    "- **35 Physik-Tests** mit detaillierten Interpretationen\n",
    "- **23 Technische Tests** (silent mode)\n",
    "- **Extended Metrics** - Zus√§tzliche Plots und Statistiken\n",
    "- **Segment-Redshift Add-on** - Gravitationelle Rotverschiebung\n",
    "\n",
    "### ‚öôÔ∏è Konfiguration anpassen\n",
    "Gehe zur√ºck zur **Konfigurations-Zelle** (oben) und √§ndere:\n",
    "```python\n",
    "ENABLE_EXTENDED_METRICS = True/False\n",
    "ENABLE_SEGMENT_REDSHIFT = True/False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "¬© 2025 Carmen Wrede, Lino Casu\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SSZ Full Pipeline",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
